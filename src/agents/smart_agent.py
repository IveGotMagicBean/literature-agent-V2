"""
æ™ºèƒ½å›¾ç‰‡åŒ¹é… - åŸºäºæ–‡æœ¬å¼•ç”¨è€Œéæå–é¡ºåº
è§£å†³PDFæå–é¡ºåºæ··ä¹±ã€å°å›¾æ ‡å™ªå£°ç­‰é—®é¢˜
"""

from pathlib import Path
from typing import Dict, List, Optional, Generator
import sys
import re

sys.path.insert(0, str(Path(__file__).parent.parent))

from parsers.pdf_parser_improved import ImprovedPDFParser
from parsers.figure_parser import FigureReferenceExtractor
from parsers.subfigure_splitter import SubfigureSplitter


class SmartAgent:
    """æ™ºèƒ½æ–‡çŒ®åŠ©æ‰‹ - åŸºäºå¼•ç”¨åŒ¹é…å›¾ç‰‡ + å­å›¾åˆ†å‰²"""
    
    def __init__(self, llm, data_dir: str = "./data"):
        self.llm = llm
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # ä½¿ç”¨æ”¹è¿›ç‰ˆPDFè§£æå™¨ - æ™ºèƒ½æå–å®Œæ•´å›¾è¡¨ï¼Œé¿å…ç¢ç‰‡
        self.pdf_parser = ImprovedPDFParser(extraction_mode="hybrid")
        
        # ä¼˜åŒ–åçš„è¿‡æ»¤å‚æ•° - æ›´å®½æ¾ï¼Œé¿å…æ¼æ‰ä¸­ç­‰å¤§å°çš„å›¾
        self.pdf_parser.min_image_size = 20000    # é™ä½åˆ°20KBï¼ˆåŸ30KBï¼‰
        self.pdf_parser.min_bbox_area = 5000      # é™ä½æœ€å°é¢ç§¯ï¼ˆåŸ8000ï¼‰
        self.pdf_parser.max_aspect_ratio = 8.0    # æ”¾å®½å®½é«˜æ¯”é™åˆ¶ï¼ˆåŸ6.0ï¼‰
        
        self.ref_extractor = FigureReferenceExtractor()
        
        # åˆå§‹åŒ–å­å›¾åˆ†å‰²å™¨
        self.splitter = SubfigureSplitter()
        
        # æ•°æ®
        self.texts = []
        self.all_images = []  # æ‰€æœ‰æå–çš„å›¾ç‰‡
        self.figure_map = {}  # Figureç¼–å· -> {"path": "...", "page": X, "subfigures": {"a": "...", "b": "..."}}
        self.full_text = ""
    
    def load_pdf(self, pdf_path: str) -> Generator[Dict, None, None]:
        """åŠ è½½PDF"""
        
        yield {"type": "status", "content": "ğŸ“„ æ­£åœ¨è§£æPDF..."}
        
        # 1. è§£æPDF
        pdf_data = self.pdf_parser.parse(pdf_path)
        self.texts = pdf_data["texts"]
        self.full_text = "\n\n".join([t["content"] for t in self.texts[:20]])
        
        yield {"type": "status", "content": f"âœ… æå–äº† {pdf_data['pages']} é¡µæ–‡æœ¬"}
        
        # 2. ä¿å­˜æ‰€æœ‰å›¾ç‰‡
        yield {"type": "status", "content": "ğŸ–¼ï¸ æ­£åœ¨æå–å›¾ç‰‡..."}
        
        image_dir = self.data_dir / "images"
        image_dir.mkdir(exist_ok=True)
        
        self.all_images = []
        for idx, fig_data in enumerate(pdf_data["figures"]):
            fig_path = image_dir / f"raw_{idx}.{fig_data['ext']}"
            with open(fig_path, "wb") as f:
                f.write(fig_data["data"])
            
            self.all_images.append({
                "id": idx,
                "path": str(fig_path),
                "page": fig_data["page"],
                "size": len(fig_data["data"])  # æ–‡ä»¶å¤§å°ï¼Œç”¨äºè¿‡æ»¤å°å›¾æ ‡
            })
        
        yield {"type": "status", "content": f"âœ… æå–äº† {len(self.all_images)} å¼ åŸå§‹å›¾ç‰‡"}
        
        # 3. **å…³é”®ï¼šé€šè¿‡æ–‡æœ¬å¼•ç”¨åŒ¹é…å›¾ç‰‡**
        yield {"type": "status", "content": "ğŸ”— æ­£åœ¨æ™ºèƒ½åŒ¹é…å›¾ç‰‡..."}
        
        self.figure_map = self._match_figures_intelligently()
        
        matched_count = len([v for v in self.figure_map.values() if v is not None])
        yield {"type": "status", "content": f"âœ… æˆåŠŸåŒ¹é… {matched_count} ä¸ªFigure"}
        
        # å®Œæˆ
        yield {
            "type": "complete",
            "stats": {
                "pages": pdf_data["pages"],
                "raw_images": len(self.all_images),
                "matched_figures": matched_count
            }
        }
    
    def _match_figures_intelligently(self) -> Dict[int, Optional[Dict]]:
        """
        æ™ºèƒ½åŒ¹é…ï¼šé€šè¿‡æ–‡æœ¬å¼•ç”¨æ‰¾åˆ°å¯¹åº”çš„å›¾ç‰‡
        
        æ”¹è¿›ç­–ç•¥ï¼š
        1. æ‰©å¤§æœç´¢èŒƒå›´ï¼ˆå‰å2é¡µï¼‰
        2. é™ä½å¤§å°é˜ˆå€¼ï¼ˆ5KBï¼‰
        3. é¿å…é‡å¤åŒ¹é…åŒä¸€å¼ å›¾
        4. å¯¹æœªåŒ¹é…çš„å¤§å›¾ä½¿ç”¨å¤‡ç”¨ç­–ç•¥
        """
        figure_map = {}
        used_image_ids = set()  # è·Ÿè¸ªå·²ä½¿ç”¨çš„å›¾ç‰‡ID
        
        # æ”¶é›†æ‰€æœ‰Figureå¼•ç”¨åŠå…¶æ‰€åœ¨é¡µ
        figure_pages = {}  # {1: [3, 5, 7], 2: [8, 9], ...}
        
        for text_data in self.texts:
            page = text_data["page"]
            refs = self.ref_extractor.extract_references(text_data["content"])
            
            for ref in refs:
                fig_num = ref["figure"]
                if fig_num not in figure_pages:
                    figure_pages[fig_num] = []
                if page not in figure_pages[fig_num]:
                    figure_pages[fig_num].append(page)
        
        print(f"[å›¾ç‰‡åŒ¹é…] æ‰¾åˆ°çš„Figureå¼•ç”¨: {dict(sorted(figure_pages.items()))}")
        
        # === ç­–ç•¥1: åŸºäºå¼•ç”¨åŒ¹é… ===
        for fig_num in sorted(figure_pages.keys()):
            pages = figure_pages[fig_num]
            # æ‰¾åˆ°ç¬¬ä¸€æ¬¡æåˆ°è¿™ä¸ªFigureçš„é¡µé¢
            first_mention_page = min(pages)
            
            # æ‰©å¤§æœç´¢èŒƒå›´ï¼šå‰å2é¡µ
            search_pages = []
            for offset in range(-2, 3):  # -2, -1, 0, 1, 2
                page = first_mention_page + offset
                if page > 0:
                    search_pages.append(page)
            
            print(f"[å›¾ç‰‡åŒ¹é…] Figure {fig_num}: é¦–æ¬¡æåŠé¡µ{first_mention_page}ï¼Œæœç´¢èŒƒå›´{search_pages}")
            
            # æ‰¾åˆ°è¿™äº›é¡µä¸Šçš„æ‰€æœ‰å›¾ç‰‡ï¼ˆæ’é™¤å·²ä½¿ç”¨çš„ï¼‰
            candidate_images = [
                img for img in self.all_images 
                if img["page"] in search_pages and img["id"] not in used_image_ids
            ]
            
            if not candidate_images:
                print(f"[å›¾ç‰‡åŒ¹é…] Figure {fig_num}: æœªæ‰¾åˆ°å¯ç”¨çš„å€™é€‰å›¾ç‰‡")
                figure_map[fig_num] = None
                continue
            
            # é€‰æ‹©æœ€å¤§çš„å›¾ç‰‡ï¼ˆæ’é™¤å°logoï¼‰
            # æé«˜é˜ˆå€¼åˆ°50KBï¼Œé¿å…æå–å°å›¾æ ‡
            large_images = [img for img in candidate_images if img["size"] > 50000]
            
            if not large_images:
                # å¦‚æœéƒ½å¾ˆå°ï¼Œé™ä½è¦æ±‚åˆ°20KB
                large_images = [img for img in candidate_images if img["size"] > 20000]
            
            if not large_images:
                # å®åœ¨æ²¡æœ‰ï¼Œå°±é€‰æœ€å¤§çš„
                large_images = candidate_images
            
            # æŒ‰å¤§å°æ’åºï¼Œé€‰æœ€å¤§çš„
            best_image = max(large_images, key=lambda x: x["size"])
            
            # æ ‡è®°ä¸ºå·²ä½¿ç”¨
            used_image_ids.add(best_image["id"])
            
            # ä¿å­˜ä¸»å›¾ä¿¡æ¯
            figure_map[fig_num] = {
                "path": best_image["path"],
                "page": best_image["page"],
                "subfigures": {},
                "split_attempted": False
            }
            
            print(f"[å›¾ç‰‡åŒ¹é…] Figure {fig_num}: âœ“ åŒ¹é…åˆ°å›¾ç‰‡ID={best_image['id']}, é¡µ{best_image['page']}, {best_image['size']/1024:.1f}KB")
        
        # === ç­–ç•¥2: å¤‡ç”¨ç­–ç•¥ - å¤„ç†æœªè¢«å¼•ç”¨ä½†å¾ˆå¤§çš„å›¾ç‰‡ ===
        # æ‰¾å‡ºæ‰€æœ‰æœªä½¿ç”¨çš„å¤§å›¾ï¼ˆ>50KBï¼Œé¿å…å°å›¾æ ‡ä½†ä¸è¦é”™è¿‡ä¸­ç­‰å›¾ï¼‰
        unmatched_large_images = [
            img for img in self.all_images 
            if img["id"] not in used_image_ids and img["size"] > 50000
        ]
        
        if unmatched_large_images:
            print(f"[å›¾ç‰‡åŒ¹é…] å‘ç° {len(unmatched_large_images)} å¼ æœªåŒ¹é…çš„å¤§å›¾(>50KB)ï¼Œå¯ç”¨å¤‡ç”¨ç­–ç•¥...")
            
            # æŒ‰é¡µé¢é¡ºåºå’Œå¤§å°æ’åº
            unmatched_large_images.sort(key=lambda x: (x["page"], -x["size"]))
            
            # åˆ†é…æ–°çš„Figureç¼–å·
            next_fig_num = max(figure_map.keys()) + 1 if figure_map else 1
            
            for img in unmatched_large_images:
                # é¿å…ç¼–å·å†²çª
                while next_fig_num in figure_map:
                    next_fig_num += 1
                
                figure_map[next_fig_num] = {
                    "path": img["path"],
                    "page": img["page"],
                    "subfigures": {},
                    "split_attempted": False
                }
                
                used_image_ids.add(img["id"])
                print(f"[å›¾ç‰‡åŒ¹é…] Figure {next_fig_num} (å¤‡ç”¨): é¡µ{img['page']}, {img['size']/1024:.1f}KB")
                
                next_fig_num += 1
        
        # æœ€ç»ˆç»Ÿè®¡
        total_matched = len([v for v in figure_map.values() if v is not None])
        print(f"[å›¾ç‰‡åŒ¹é…] å®Œæˆ: å…±åŒ¹é… {total_matched} ä¸ªFigure (åŸºäºå¼•ç”¨: {len(figure_pages)}, å¤‡ç”¨ç­–ç•¥: {len(unmatched_large_images)})")
        
        return figure_map
    
    def query(self, question: str) -> Generator[Dict, None, None]:
        """å›ç­”é—®é¢˜"""
        
        if not self.texts:
            yield {"type": "error", "content": "è¯·å…ˆä¸Šä¼ PDFæ–‡çŒ®"}
            return
        
        print(f"[DEBUG] é—®é¢˜: {question}")
        yield {"type": "thinking", "content": "ğŸ” æ­£åœ¨åˆ†æ..."}
        
        # 1. æå–Figureç¼–å·ï¼ˆæ”¯æŒå­å›¾ï¼‰
        fig_ref = self._extract_figure_number(question)
        
        if fig_ref:
            fig_num = fig_ref["number"]
            subfig = fig_ref.get("subfigure")  # å¯èƒ½æ˜¯ "a", "b" ç­‰
            
            print(f"[DEBUG] æŸ¥è¯¢ Figure {fig_num}{subfig or ''}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…åˆ°è¿™ä¸ªFigure
            if fig_num in self.figure_map and self.figure_map[fig_num]:
                fig_data = self.figure_map[fig_num]
                
                # **å»¶è¿Ÿåˆ†å‰²ï¼šåªåœ¨éœ€è¦å­å›¾æ—¶æ‰åˆ†å‰²**
                if subfig and not fig_data.get("split_attempted", False):
                    # ç”¨æˆ·è¯¢é—®å­å›¾ï¼Œä½†è¿˜æ²¡åˆ†å‰²è¿‡
                    if self.splitter.is_available():
                        yield {"type": "status", "content": f"ğŸ” æ£€æµ‹ Figure {fig_num} æ˜¯å¦åŒ…å«å­å›¾..."}
                        
                        try:
                            subfigs = self.splitter.split(
                                fig_data["path"],
                                str(self.data_dir / "images"),
                                fig_num
                            )
                            
                            fig_data["subfigures"] = subfigs
                            fig_data["split_attempted"] = True
                            
                            if subfigs:
                                subfig_labels = ", ".join(subfigs.keys())
                                yield {"type": "status", "content": f"âœ… æˆåŠŸåˆ†å‰²å‡º {len(subfigs)} ä¸ªå­å›¾: {subfig_labels}"}
                                
                                # è¿”å›æ‰€æœ‰å­å›¾ï¼Œæ·»åŠ åˆ°ä¾§è¾¹æ 
                                for label, path in subfigs.items():
                                    image_filename = Path(path).name
                                    yield {
                                        "type": "figure",
                                        "data": {
                                            "path": f"images/{image_filename}",
                                            "label": f"Figure {fig_num}{label}",
                                            "page": fig_data["page"],
                                            "type": "subfigure"
                                        }
                                    }
                            else:
                                yield {"type": "status", "content": f"â„¹ï¸  Figure {fig_num} æœªæ£€æµ‹åˆ°å­å›¾ï¼Œå°†ä½œä¸ºæ•´å›¾åˆ†æ"}
                        except Exception as e:
                            yield {"type": "status", "content": f"âš ï¸  å­å›¾åˆ†å‰²å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨å®Œæ•´å›¾ç‰‡"}
                            fig_data["split_attempted"] = True
                    else:
                        yield {"type": "status", "content": f"â„¹ï¸  å­å›¾åˆ†å‰²åŠŸèƒ½æœªå¯ç”¨ï¼Œå°†ä½¿ç”¨å®Œæ•´å›¾ç‰‡"}
                        fig_data["split_attempted"] = True
                
                # å¦‚æœè¯¢é—®çš„æ˜¯æ•´å›¾ä½†è¿˜æ²¡åˆ†å‰²è¿‡ï¼Œä¹Ÿå°è¯•åˆ†å‰²ï¼ˆå¯èƒ½æœ‰å­å›¾ï¼‰
                elif not subfig and not fig_data.get("split_attempted", False):
                    if self.splitter.is_available():
                        yield {"type": "status", "content": f"ğŸ” æ­£åœ¨æ£€æµ‹ Figure {fig_num} çš„å­å›¾..."}
                        
                        try:
                            subfigs = self.splitter.split(
                                fig_data["path"],
                                str(self.data_dir / "images"),
                                fig_num
                            )
                            
                            fig_data["subfigures"] = subfigs
                            fig_data["split_attempted"] = True
                            
                            if subfigs:
                                subfig_labels = ", ".join(subfigs.keys())
                                yield {"type": "status", "content": f"ğŸ’¡ æ£€æµ‹åˆ° {len(subfigs)} ä¸ªå­å›¾ ({subfig_labels})ï¼Œå¦‚éœ€å•ç‹¬åˆ†æå¯æŒ‡å®šå­å›¾ç¼–å·"}
                                
                                # è¿”å›æ‰€æœ‰å­å›¾ï¼Œæ·»åŠ åˆ°ä¾§è¾¹æ 
                                for label, path in subfigs.items():
                                    image_filename = Path(path).name
                                    yield {
                                        "type": "figure",
                                        "data": {
                                            "path": f"images/{image_filename}",
                                            "label": f"Figure {fig_num}{label}",
                                            "page": fig_data["page"],
                                            "type": "subfigure"
                                        }
                                    }
                        except Exception as e:
                            print(f"[DEBUG] å­å›¾åˆ†å‰²å¤±è´¥: {e}")
                            fig_data["split_attempted"] = True
                
                # **å…³é”®ï¼šé€‰æ‹©æ­£ç¡®çš„å›¾ç‰‡**
                if subfig and subfig in fig_data.get("subfigures", {}):
                    # ç”¨æˆ·é—®å­å›¾ â†’ åªç»™æ¨¡å‹çœ‹å­å›¾ï¼
                    image_path = fig_data["subfigures"][subfig]
                    label = f"Figure {fig_num}{subfig}"
                    print(f"[DEBUG] ä½¿ç”¨å­å›¾: {image_path}")
                else:
                    # ç”¨æˆ·é—®ä¸»å›¾ â†’ ç»™å®Œæ•´å›¾
                    image_path = fig_data["path"]
                    label = f"Figure {fig_num}"
                    if subfig:
                        print(f"[DEBUG] æœªæ‰¾åˆ°å­å›¾{subfig}ï¼Œä½¿ç”¨å®Œæ•´å›¾")
                    print(f"[DEBUG] ä½¿ç”¨ä¸»å›¾: {image_path}")
                
                # è¿”å›å›¾ç‰‡ï¼ˆä¿®å¤ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
                # å»æ‰è·¯å¾„å‰ç¼€ï¼Œåªä¿ç•™æ–‡ä»¶å
                image_filename = Path(image_path).name
                
                if subfig:
                    yield {"type": "thinking", "content": f"ğŸ“ æ‰¾åˆ° Figure {fig_num}{subfig}"}
                else:
                    yield {"type": "thinking", "content": f"ğŸ“ æ‰¾åˆ° Figure {fig_num}"}
                
                yield {
                    "type": "figure",
                    "data": {
                        "path": f"images/{image_filename}",  # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                        "label": label,
                        "page": fig_data["page"]
                    }
                }
                
                # **ç«‹å³åˆ†æå›¾ç‰‡ï¼ˆä¸éœ€è¦ç”¨æˆ·å†é—®ï¼‰**
                yield {"type": "thinking", "content": "ğŸ‘€ æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹..."}
                
                # è·å–æ–‡ä¸­æè¿°
                description = self._get_figure_description(fig_num, subfig)
                
                # æ„å»ºåˆ†æprompt
                analysis_prompt = f"""è¯·åˆ†æè¿™ä¸ª{'å­' if subfig else ''}å›¾ã€‚

é—®é¢˜ï¼š{question}

æ–‡ä¸­æè¿°ï¼š
{description}

è¯·è¯¦ç»†åˆ†æå›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. å›¾ç‰‡å±•ç¤ºçš„å†…å®¹
2. å…³é”®ä¿¡æ¯å’Œæ•°æ®
3. ä¸ç ”ç©¶çš„å…³ç³»

ç”¨ä¸­æ–‡å›ç­”ã€‚"""
                
                # ä½¿ç”¨LLMåˆ†æ
                try:
                    messages = [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®åˆ†æåŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": analysis_prompt}
                    ]
                    
                    full_answer = ""
                    for chunk in self.llm.stream_chat(messages):
                        full_answer += chunk
                        yield {"type": "answer_chunk", "content": chunk}
                    
                    if not full_answer:
                        # æµå¼å¤±è´¥ï¼Œå°è¯•æ™®é€šè°ƒç”¨
                        full_answer = self.llm.chat(messages)
                        yield {"type": "answer", "content": full_answer}
                    else:
                        yield {"type": "answer_done", "content": full_answer}
                except Exception as e:
                    print(f"[ERROR] å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
                    # è¿”å›æ–‡æœ¬æè¿°
                    answer = f"**{label}** (ç¬¬{fig_data['page']}é¡µ)\n\n{description}"
                    yield {"type": "answer", "content": answer}
                
                return
            else:
                yield {"type": "error", "content": f"æœªæ‰¾åˆ° Figure {fig_num}ï¼ˆå¯èƒ½æ–‡ä¸­æœªæåŠæˆ–å›¾ç‰‡æå–å¤±è´¥ï¼‰"}
                return
        
        # ... åç»­ä»£ç ä¸å˜ ...
        
        # 2. æ¨¡ç³Šå›¾ç‰‡æœç´¢
        if self._is_figure_question(question):
            yield {"type": "thinking", "content": "ğŸ” æ­£åœ¨æœç´¢ç›¸å…³å›¾ç‰‡..."}
            
            best_fig = self._search_figure_by_description(question)
            
            if best_fig:
                fig_num, score = best_fig
                img_info = self.figure_map[fig_num]
                
                yield {"type": "thinking", "content": f"ğŸ“ æ‰¾åˆ° Figure {fig_num} (ç›¸å…³åº¦ {score:.0%})"}
                
                yield {
                    "type": "figure",
                    "data": {
                        "path": img_info["path"],
                        "label": f"Figure {fig_num}",
                        "page": img_info["page"]
                    }
                }
                
                description = self._get_figure_description(fig_num)
                answer = f"æ ¹æ®æ–‡ä¸­æè¿°ï¼Œ**Figure {fig_num}**æœ€ç›¸å…³ï¼š\n\n{description}"
                
                yield {"type": "answer", "content": answer}
                return
        
        # 3. æ–‡æœ¬é—®ç­”
        yield {"type": "thinking", "content": "ğŸ’­ æ­£åœ¨ç”Ÿæˆå›ç­”..."}
        
        # ç®€å•é—®å€™
        greetings = ["ä½ å¥½", "æ‚¨å¥½", "hi", "hello"]
        if any(g in question.lower() for g in greetings):
            answer = """ä½ å¥½ï¼æˆ‘æ˜¯æ–‡çŒ®é˜…è¯»åŠ©æ‰‹ã€‚

æˆ‘å¯ä»¥å¸®ä½ ï¼š
- ğŸ“– ç†è§£æ–‡çŒ®å†…å®¹
- ğŸ–¼ï¸ æŸ¥æ‰¾å›¾ç‰‡ï¼ˆé€šè¿‡Figureç¼–å·æˆ–æè¿°ï¼‰
- ğŸ’¬ å›ç­”é—®é¢˜

è¯•è¯•é—®ï¼š
â€¢ "Figure 1å±•ç¤ºäº†ä»€ä¹ˆï¼Ÿ"
â€¢ "è¿™ç¯‡æ–‡ç« çš„ä¸»è¦æ–¹æ³•ï¼Ÿ"
â€¢ "å“ªå¼ å›¾å±•ç¤ºäº†æ¶æ„ï¼Ÿ"
"""
            yield {"type": "answer", "content": answer}
            return
        
        # æ£€ç´¢ç›¸å…³æ–‡æœ¬
        relevant = self._search_text(question, top_k=5)
        
        if relevant:
            context = "\n\n".join(relevant)
        else:
            context = self.full_text[:3000]
        
        prompt = f"""è¯·æ ¹æ®æ–‡çŒ®å†…å®¹å›ç­”é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

æ–‡çŒ®å†…å®¹ï¼š
{context}

è¯·ç”¨ä¸­æ–‡è¯¦ç»†å›ç­”ã€‚"""
        
        # LLMå›ç­”
        try:
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®é˜…è¯»åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            full_answer = ""
            for chunk in self.llm.stream_chat(messages):
                full_answer += chunk
                yield {"type": "answer_chunk", "content": chunk}
            
            if not full_answer:
                # å¦‚æœæµå¼å¤±è´¥ï¼Œå°è¯•æ™®é€šè°ƒç”¨
                full_answer = self.llm.chat(messages)
                yield {"type": "answer", "content": full_answer}
            else:
                yield {"type": "answer_done", "content": full_answer}
        except Exception as e:
            print(f"[ERROR] LLMè°ƒç”¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield {"type": "error", "content": f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"}
    
    def _extract_figure_number(self, text: str) -> Optional[Dict]:
        """æå–Figureç¼–å·ï¼ˆæ”¯æŒå­å›¾ï¼Œæ”¯æŒä¸­æ–‡ï¼‰"""
        patterns = [
            # Figure 1a, Figure 1.a, Figure 1(a), Figure 1-a
            (r'[Ff]igure?\s*(\d+)\s*[-\.\(]?\s*([a-zA-Z])\s*[\)]?', True),
            # Fig. 1a, Fig 1a
            (r'[Ff]ig\.?\s*(\d+)\s*[-\.\(]?\s*([a-zA-Z])\s*[\)]?', True),
            # å›¾1a, å›¾1-a, å›¾1.a, å›¾ 1 a
            (r'å›¾\s*(\d+)\s*[-\.\(]?\s*([a-zA-Z])\s*[\)]?', True),
            # ä¸­æ–‡ï¼šå›¾1å­å›¾a, å›¾1çš„å­å›¾a  
            (r'å›¾\s*(\d+)\s*(?:çš„)?å­å›¾\s*([a-zA-Z])', True),
            # ä¸­æ–‡ï¼šfigure1å­å›¾c
            (r'[Ff]igure?\s*(\d+)\s*å­å›¾\s*([a-zA-Z])', True),
            # Figure 1 (without subfigure)
            (r'[Ff]igure?\s*(\d+)(?!\s*[a-zA-Z])', False),
            # Fig. 1
            (r'[Ff]ig\.?\s*(\d+)(?!\s*[a-zA-Z])', False),
            # å›¾1
            (r'å›¾\s*(\d+)(?!\s*[a-zA-Z])', False),
        ]
        
        for pattern, has_subfig in patterns:
            match = re.search(pattern, text)
            if match:
                result = {"number": int(match.group(1))}
                if has_subfig and len(match.groups()) > 1:
                    result["subfigure"] = match.group(2).lower()  # ç»Ÿä¸€è½¬å°å†™
                return result
        
        return None
    
    def _is_figure_question(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦å›¾ç‰‡é—®é¢˜"""
        keywords = ["å“ªå¼ å›¾", "ä»€ä¹ˆå›¾", "å›¾ç‰‡", "figure", "å±•ç¤º", "æ˜¾ç¤º", "æ¶æ„", "æµç¨‹"]
        return any(kw in text.lower() for kw in keywords)
    
    def _get_figure_description(self, fig_num: int, subfig: Optional[str] = None) -> str:
        """è·å–Figureçš„æ–‡ä¸­æè¿°ï¼ˆæ”¯æŒå­å›¾ï¼‰"""
        descriptions = []
        
        for text_data in self.texts:
            refs = self.ref_extractor.extract_references(text_data["content"])
            
            for ref in refs:
                # å¦‚æœæŒ‡å®šäº†å­å›¾ï¼ŒåªåŒ¹é…è¯¥å­å›¾
                if ref["figure"] == fig_num:
                    if subfig:
                        # æŸ¥è¯¢å­å›¾ï¼Œåªè¿”å›æåˆ°è¯¥å­å›¾çš„æè¿°
                        if ref.get("subfigure") == subfig:
                            context = self.ref_extractor.get_context(text_data["content"], ref, 250)
                            descriptions.append(context)
                    else:
                        # æŸ¥è¯¢ä¸»å›¾ï¼Œè¿”å›æ‰€æœ‰æè¿°
                        context = self.ref_extractor.get_context(text_data["content"], ref, 250)
                        descriptions.append(context)
        
        if descriptions:
            # å»é‡å¹¶é™åˆ¶æ•°é‡
            unique_desc = []
            seen = set()
            for desc in descriptions:
                if desc not in seen:
                    unique_desc.append(desc)
                    seen.add(desc)
                    if len(unique_desc) >= 3:
                        break
            
            return "\n\n".join(unique_desc)
        else:
            if subfig:
                return f"æ–‡ä¸­æœªæ‰¾åˆ°å…³äºFigure {fig_num}{subfig}çš„æ˜ç¡®æè¿°ã€‚"
            else:
                return f"æ–‡ä¸­æœªæ‰¾åˆ°å…³äºFigure {fig_num}çš„æ˜ç¡®æè¿°ã€‚"
    
    def _search_figure_by_description(self, query: str) -> Optional[tuple]:
        """æ ¹æ®æè¿°æœç´¢Figure"""
        best_fig = None
        best_score = 0
        
        for fig_num in self.figure_map.keys():
            desc = self._get_figure_description(fig_num)
            score = self._similarity(query, desc)
            
            if score > best_score:
                best_score = score
                best_fig = (fig_num, score)
        
        if best_score > 0.2:
            return best_fig
        return None
    
    def _search_text(self, query: str, top_k: int = 5) -> List[str]:
        """æ£€ç´¢æ–‡æœ¬"""
        query_words = set(w for w in query.lower().split() if len(w) > 1)
        
        if not query_words:
            return [t["content"] for t in self.texts[:3]]
        
        scored = []
        for text_data in self.texts:
            content = text_data["content"]
            content_words = set(content.lower().split())
            
            score = len(query_words & content_words) * 2
            
            for word in query_words:
                if len(word) > 2 and word in content.lower():
                    score += 5
            
            if score > 0:
                scored.append((score, content))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        
        if not scored:
            return [t["content"] for t in self.texts[:3]]
        
        return [text for _, text in scored[:top_k]]
    
    def _similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1:
            return 0.0
        
        return len(words1 & words2) / len(words1)
    
    def _is_english(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡"""
        # ç®€å•åˆ¤æ–­ï¼šå¦‚æœè‹±æ–‡å­—ç¬¦å æ¯”>60%ï¼Œè®¤ä¸ºæ˜¯è‹±æ–‡
        english_chars = sum(1 for c in text if c.isascii() and c.isalpha())
        total_chars = sum(1 for c in text if c.isalpha())
        
        if total_chars == 0:
            return False
        
        return english_chars / total_chars > 0.6
    
    def auto_split_all_figures(self):
        """è‡ªåŠ¨åˆ†å‰²æ‰€æœ‰Figureçš„å­å›¾"""
        if not self.splitter.is_available():
            print("âš ï¸  å­å›¾åˆ†å‰²å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡è‡ªåŠ¨åˆ†å‰²")
            return
        
        print("ğŸ” å¼€å§‹è‡ªåŠ¨åˆ†å‰²å­å›¾...")
        total_subfigures = 0
        
        for fig_num, fig_data in list(self.figure_map.items())[:5]:  # é™åˆ¶å‰5ä¸ª
            if not fig_data or fig_data.get("split_attempted"):
                continue
            
            try:
                print(f"  åˆ†å‰² Figure {fig_num}...")
                subfigs = self.splitter.split(
                    fig_data["path"],
                    str(self.data_dir / "images"),
                    fig_num,
                    use_numbers=True
                )
                
                if subfigs:
                    fig_data["subfigures"] = subfigs
                    fig_data["split_attempted"] = True
                    total_subfigures += len(subfigs)
                    print(f"  âœ… Figure {fig_num}: {len(subfigs)} ä¸ªå­å›¾")
                else:
                    fig_data["split_attempted"] = True
                    print(f"  â„¹ï¸  Figure {fig_num}: æ— å­å›¾")
                    
            except Exception as e:
                print(f"  âŒ Figure {fig_num} åˆ†å‰²å¤±è´¥: {e}")
                fig_data["split_attempted"] = True
                continue
        
        if total_subfigures > 0:
            print(f"âœ… è‡ªåŠ¨åˆ†å‰²å®Œæˆï¼Œå…± {total_subfigures} ä¸ªå­å›¾")
        else:
            print("â„¹ï¸  æœªæ£€æµ‹åˆ°å¤åˆå›¾")

